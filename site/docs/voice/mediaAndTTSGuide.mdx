---
id: mediaAndTTSGuide
title: Media and TTS Guide
slug: /voice/guides/mediaAndTTS
description: How to play media and use Bandwidth's text-to-speech (TTS) on a call.
keywords:
  - bandwidth
  - voice
  - TTS
  - media
  - tutorial
hide_title: false
image: ../../static/img/bandwidth-logo.png
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

In this guide we will show you how to play media and use text to speech for calls. Please ensure you have followed our earlier guide on [how to make an outbound call](/docs/voice/guides/outboundCall) with Bandwidth.

You may want to play media for on-hold music or use text-to-speech to play descriptive messages to your customers.

### Play Media

The BXML PlayAudio verb is used to play an audio file in the call. After creating the call via our API, your associated voice application should contain this BXML.

The audio file should already be hosted and the URL of an audio file should be included in the body of the `<PlayAudio>` tag. However, it may be a relative URL that is then hosted by your device.

<Tabs
    groupId="bxml"
    defaultValue="xml"
    values={[
        { label: 'XML', value: 'xml', },
        { label: 'Java', value: 'java', },
        { label: 'C#', value: 'csharp', },
        { label: 'Ruby', value: 'ruby', },
        { label: 'NodeJS', value: 'nodejs', },
        { label: 'Python', value: 'python', },
        { label: 'PHP', value: 'php', },
    ]
}>
<TabItem value="xml">

```xml
<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <SpeakSentence>Hello! Here is a sponsored message.</SpeakSentence>
    <PlayAudio>https://audio.url/audio1.wav</PlayAudio>
    <PlayAudio>/relative_endpoint_that_delivers_mediafile</PlayAudio>
</Response>
```

</TabItem>
<TabItem value="java">
**Note: This application is pseudocoded. Your implementation will look different

```java
@Post /play_audio endpoint
public String playaudio() {
    Response response = new Response();

    PlayAudio play_first = PlayAudio.builder().audioUri("https://IPlayAudio.test/audio1").build();
    PlayAudio play_second = PlayAudio.builder().audioUri("/relative_audio").build();

    String bxml = response.addAll(play_first, play_second).toBXML();

    return bxml;
}

@Get /relative_audio endpoint
public byte[] getAudio() {
    ...retrieve and return audio file...
}
```
The second instance of PlayAudio (a relative endpoint) assumes there is an endpoint in the application that serves an audio file. To see an example, look [here](https://github.com/Bandwidth-Samples/voice-record-java/blob/main/src/main/java/com/bandwidth/controller/FilesController.java).

</TabItem>
<TabItem value="csharp">
**Note: The endpoint headers are pseudocoded. Your implementation will look different

```csharp
@Post [/playaudio]
public ActionResult playAudio() {
    PlayAudio playAudio1 = new PlayAudio {
        Url = "https://audio.url/audio1.wav"
    };

    PlayAudio playAudio2 = new PlayAudio {
        Url = "/relative_audio"
    };

    Response response = new Response();
    response.Add(playAudio1);
    response.Add(playAudio2);

    return new OkObjectResult(response.ToBXML());
}

@Get [/relative_audio]
public ActionResult getAudio()
{
    ...retrieve and return audio file...
}
```
The second instance of PlayAudio (a relative endpoint) assumes there is an endpoint in the application that serves an audio file. To see an example, look [here](https://github.com/Bandwidth-Samples/voice-record-java/blob/main/src/main/java/com/bandwidth/controller/FilesController.java).

</TabItem>
<TabItem value="ruby">
**Note: This application is pseudocoded. Your implementation will look different

```ruby
post '/playAudio' do:
    play_audio_1 = Bandwidth::Voice::PlayAudio.new({
        :url => "https://audio.url/audio1.wav"
    })

    play_audio_2 = Bandwidth::Voice::PlayAudio.new({
        :url => "/relative_audio"
    })

    response = Bandwidth::Voice::Response.new()
    response.push(play_audio_1)
    response.push(play_audio_2)

    return response.to_bxml()

get '/relative_audio' do:
    ...retrieve and return audio file...
```
The second instance of PlayAudio (a relative endpoint) assumes there is an endpoint in the application that serves an audio file. To see an example, look [here](https://github.com/Bandwidth-Samples/voice-record-java/blob/main/src/main/java/com/bandwidth/controller/FilesController.java).

</TabItem>
<TabItem value="nodejs">
**Note: The endpoint headers are pseudocoded. Your implementation will look different

```js
@post ['/playAudio'] (request, request_response) => {
    const playAudio1 = new PlayAudio({
        url: "https://audio.url/audio1.wav"
    });

    const playAudio2 = new PlayAudio({
        url: "/relative_audio"
    });

    const response = new Response(playAudio1, playAudio2);

    console.log(response.toBxml());
    request_response.status(200).send(response.toBxml());

}

@get ['/relative_audio'] => {
    ...retrieve and return audio file...
}
```
The second instance of PlayAudio (a relative endpoint) assumes there is an endpoint in the application that serves an audio file. To see an example, look [here](https://github.com/Bandwidth-Samples/voice-record-java/blob/main/src/main/java/com/bandwidth/controller/FilesController.java).


</TabItem>
<TabItem value="python">
**Note: The endpoint headers are pseudocoded. Your implementation will look different

```python
@post '/playAudio'
def playAudio():
    play_audio_1 = PlayAudio(
        url="https://audio.url/audio1.wav"
    )

    play_audio_2 = PlayAudio(
        url="/relative_audio"
    )

    response = Response()
    response.add_verb(play_audio_1)
    response.add_verb(play_audio_2)

    return response.to_bxml()

@get '/relative_audio'
def getAudio():
    ...retrieve and return audio file...

```
The second instance of PlayAudio (a relative endpoint) assumes there is an endpoint in the application that serves an audio file. To see an example, look [here](https://github.com/Bandwidth-Samples/voice-record-java/blob/main/src/main/java/com/bandwidth/controller/FilesController.java).

</TabItem>
<TabItem value="php">
**Note: The endpoint headers are pseudocoded. Your implementation will look different

```php
@post('/playAudio)
function playAudio(Request $request, Response $response) {
    $playAudio1 = new BandwidthLib\Voice\Bxml\PlayAudio("https://audio.url/audio1.wav");
    $playAudio2 = new BandwidthLib\Voice\Bxml\PlayAudio("https://audio.url/audio2.mp3");

    $response = new BandwidthLib\Voice\Bxml\Response();
    $response->addVerb($playAudio1);
    $response->addVerb($playAudio2);

    $bxml = $bxmlResponse->toBxml();
    $response = $response->withStatus(200)->withHeader('Content-Type', 'application/xml');
    $response->getBody()->write($bxml);
    return $response;
}

@get('/relative_audio)
function getAudio(Request $request, Response $response) {
    ...retrieve and return audio file...
}
```
The second instance of PlayAudio (a relative endpoint) assumes there is an endpoint in the application that serves an audio file. To see an example, look [here](https://github.com/Bandwidth-Samples/voice-record-java/blob/main/src/main/java/com/bandwidth/controller/FilesController.java).


</TabItem>
</Tabs>

In this example, once the call is created using our API we check the specific answerUrl for a BXML response which tells us to play the media file. You also have the ability to play multiple audio files in succession.

:::tip
ONLY .wav and .mp3 files as are supported

To ensure playback quality, Bandwidth recommends limiting audio files to less than 1 hour in length or 250 MB in size.
:::

### Text-To-Speech

The SpeakSentence verb is used for text-to-speech playback on a call. Attributes of the speaker may be changed including the gender or locale of the speaker. The default speaker is a female speaker with locale en_US.

<Tabs
    groupId="bxml"
    defaultValue="xml"
    values={[
        { label: 'XML', value: 'xml', },
        { label: 'Java', value: 'java', },
        { label: 'C#', value: 'csharp', },
        { label: 'Ruby', value: 'ruby', },
        { label: 'NodeJS', value: 'nodejs', },
        { label: 'Python', value: 'python', },
        { label: 'PHP', value: 'php', },
    ]
}>
<TabItem value="xml">

```xml
<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <SpeakSentence voice="jorge">
        Hello <lang xml:lang="en-GB">Sherlock Holmes</lang>.
        You have an appointment on <say-as interpret-as="date" format="mdy">11/12/2022</say-as>.
    </SpeakSentence>
</Response>
```

</TabItem>
<TabItem value="java">
**Note: The endpoint headers are pseudocoded. Your implementation will look different

```java
@Post /tts endpoint
public String speakSentence() {
    Response response = new Response();

    SpeakSentence speakSentence = SpeakSentence.builder()
    .text("Hello <lang xml:lang=\"en-GB\">Sherlock Holmes</lang>. You have an appointment on <say-as interpret-as="date" format="mdy">11/12/2022</say-as>.")
    .voice("jorge")
    .build();

    String bxml = response.add(speakSentence).toBXML();

    return bxml;
}
```

</TabItem>
<TabItem value="csharp">
**Note: The endpoint headers are pseudocoded. Your implementation will look different

```csharp
@Post [/tts]
public ActionResult speaksentence() {
    Response response = new Response();

    SpeakSentence speakSentence = new SpeakSentence {
        Sentence = "Hello <lang xml:lang=\"en-GB\">Sherlock Holmes</lang>. You have an appointment on <say-as interpret-as="date" format="mdy">11/12/2022</say-as>.",
        Voice = "jorge"
    };

    Response response = new Response();
    response.Add(speakSentence);

    return new OkObjectResult(response.ToBXML());
}
```

</TabItem>
<TabItem value="ruby">
**Note: The endpoint headers are pseudocoded. Your implementation will look different

```
~post '/tts' do:
    speak_sentence = Bandwidth::Voice::SpeakSentence.new({
        :sentence => 'Hello <lang xml:lang="en-GB">Sherlock Holmes</lang>. You have an appointment on <say-as interpret-as="date" format="mdy">11/12/2022</say-as>.',
        :voice => "jorge"
    })

    response = Bandwidth::Voice::Response.new()
    response.push(speak_sentence)

    return response.to_bxml()

```

</TabItem>
<TabItem value="nodejs">
**Note: The endpoint headers are pseudocoded. Your implementation will look different

```js
~POST ['/playAudio'] (req, res) => {
    const speakSentence = new SpeakSentence({
        sentence: `Hello <lang xml:lang="en-GB">Sherlock Holmes</lang>. You have an appointment on <say-as interpret-as="date" format="mdy">11/12/2022</say-as>.`,
        voice: "jorge"
    });

    const response = new Response(speakSentence);

    console.log(response.toBxml());
    request_response.status(200).send(response.toBxml());
}
```

</TabItem>
<TabItem value="python">
**Note: The endpoint headers are pseudocoded. Your implementation will look different

```python
@post '/playAudio'
def playAudio():
    speak_sentence = SpeakSentence(
        sentence='Hello <lang xml:lang="en-GB">Sherlock Holmes</lang>. You have an appointment on <say-as interpret-as="date" format="mdy">11/12/2022</say-as>.',
        voice="jorge"
    )

    response = Response()
    response.add_verb(speak_sentence)

    return response.to_bxml()
```

</TabItem>
<TabItem value="php">
**Note: The endpoint headers are pseudocoded. Your implementation will look different

```php
@post('/playAudio)
function playAudio(Request $request, Response $response) {
    $speakSentence = new BandwidthLib\Voice\Bxml\SpeakSentence('Hello <lang xml:lang="en-GB">Sherlock Holmes</lang>. You have an appointment on <say-as interpret-as="date" format="mdy">11/12/2022</say-as>.');
    $speakSentence->voice("jorge");

    $response = new BandwidthLib\Voice\Bxml\Response();
    $response->addVerb($speakSentence);

    $bxml = $bxmlResponse->toBxml();
    $response = $response->withStatus(200)->withHeader('Content-Type', 'application/xml');
    $response->getBody()->write($bxml);
    return $response;
}
```

</TabItem>
</Tabs>

In this example, once the call is created using our API we check the specific answerUrl for a BXML response which tells us to playback the specified text.

SSML tags are allowed to provide you with additional functionality. In the example, the name Sherlock Holmes is said with British inflection, and the date is pronounced as "November twelfth, twenty-twenty-two" instead of the numbers being read. To see details of other SSML tags, check [speaksentence](/docs/voice/bxml/speakSentence).

### Where to next?

Now that you have made your first outbound call with playing media or text-to-speech, some of the available actions are available in the following guides:
- [How to record calls & transcribe](/docs/voice/guides/recording)
- [How to gather user input (IVR)](/docs/voice/guides/interactiveVoiceResponse)
- [How to use voicemail detection](/docs/voice/guides/machineDetection)
- [How to create conference calls](/docs/voice/guides/conference)
